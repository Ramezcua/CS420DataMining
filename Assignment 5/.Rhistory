library(arules)
data(Groceries)
fix(Groceries)
View(Groceries)
as.dataframe(Groceries)
?as
dataframe
?dataframe
as.frame()
?as
fix(Groceries)
?transaction
?transactions
?transactionInfor
?transactionInfo
signature(from=Groceries, to="data.frame")
as(Groceries, "data.frame")
i <- as(Groceries, "data.frame")
View(i)
i <- as(Groceries, "matrix")
View(i)
summary(Groceries)
?apriori
data("Adult")
fix(Adult)
rm(Adult)
rules <- apriori(Groceries)
library(arulesViz)
plot(rules)
rules
rules <- apriori(Groceries)
?apriori
rules <- apriori(Groceries, parameter = list(supp = 000.1, conf = 0.7, target = "rules"))
rules
rules <- apriori(Groceries, parameter = list(supp = 0.01, conf = 0.7, target = "rules"))
rules <- apriori(Groceries, parameter = list(supp = 0.01, conf = 0.1, target = "rules"))
rules
plot(rules)
rules <- apriori(Groceries, parameter = list(supp = 0.1, conf = 0.1, target = "rules"))
rules
plot(rules)
rules <- apriori(Groceries, parameter = list(supp = 0.01, conf = 0.1, target = "rules"))
rules
plot(rules)
rules <- apriori(Groceries, parameter = list(supp = 0.01, conf = 0.01, target = "rules"))
rules
summary(rules)
inspect(head(sort(rules, by-"lift"), 3))
inspect(head(sort(rules, by="lift"), 3))
inspect(head(sort(rules, by="support"), 3))
inspect(head(sort(rules, by="support"), 10))
inspect(head(sort(rules, by="lift"), 10))
inspect(head(sort(rules, by="confidence"), 10))
plot(rules)
rules <- apriori(Groceries, parameter = list(supp = 0.001, conf = 0.001, target = "rules"))
rules
plot(rules)
inspect(head(sort(rules, by="support"), 10))
inspect(head(sort(rules, by="lift"), 10))
inspect(head(sort(rules, by="confidence"), 10))
rules <- apriori(Groceries, parameter = list(supp = 0.005, conf = 0.005, target = "rules"))
rules
plot(rules)
rules <- apriori(Groceries, parameter = list(supp = 0.01, conf = 0.01, target = "rules"))
iris
?kmeans
DIFF.THRESH = 0
#### Functions ####
# This function is used to normal data in a data frame
# It takes a data frame and the number of attributes in that data frame
NormalizeData <- function(df, natt){
for(i in 1:natt){
stan <- sd(df[,i])
mean <- mean(df[,i])
df[,i] <- sapply(df[,i], FUN = function(x){
return ((x-mean)/stan)}) # nvm (Added a rounding function here round(x, 3))
}
return (df)
}
# This function will update the centroids
# It takes the dataframe of the data, a dataframe with the centroids data
# and the k
UpdateCentroids <- function(df, centroids, k){
for(i in 1:k){
temp <- subset(df, Cluster == i)
temp$Cluster <- NULL # Remove clusters
centroids[i,]<-as.vector(colMeans(temp))
}
return (centroids)
}
# This function will find the Euclidean distance between two points
EuclideanDistance <- function(p1, p2){
distance <- p1-p2
distance <- sapply(distance, FUN=function(x){return(x^2)})
distance <- sum(distance)
distance <- sqrt(distance)
return (distance)
}
# This function takes a point and the centroids data frame
# It will find the centroid closest to that point (returns the index)
FindCluster <- function(point, centroids){
k <- nrow(centroids)
distances <- NULL
for(i in 1:k){
distances <- append(distances, EuclideanDistance(point, centroids[i,]))
}
#print(distances)
cluster <- which(distances==(min(distances)))
return(cluster[1])
}
# This is a helper function that checks if a set of clusters is in
# the currently active set of clusters.
# It returns a list of inactive clusters, or 0 if all clusters are active
ClusterRepCheck <- function(clusters, active.clusters){
active.clusters <- unique(active.clusters)
inactive.clusters <- which(!(clusters %in% active.clusters))
if(length(inactive.clusters) == 0){inactive.clusters <-0}
return(inactive.clusters)
}
# This function has the stopping condition for the k - means algo
# It takes two sets of cluster as vectors and finds the difference percentage
# (number of differences)/length
# It also takes a threshold for the difference percentage
StoppingCondition <- function(previous.clusters, current.clusters, threshold){
stopping.condition <- FALSE
num.differences <- length(which(previous.clusters != current.clusters))
# If the number of differences falls below a certain threshold, stop the algo
difference.percentage <- num.differences/length(current.clusters)
#print(difference.percentage)
if (difference.percentage <= threshold){stopping.condition <- TRUE}
return(stopping.condition)
}
# This is my kmeans function.  It takes a data frame of data and a k
# It returns a vector of the clusters associated with the data
MyKMeans <-function(df, k, measure.SSE=FALSE){
natt <- ncol(df)
centroids <- as.data.frame(matrix(data=0, nrow=k, ncol=natt))
# Adding a cluster column and randomly assigning each point to a cluster
df["Cluster"] <- NA
df$Cluster <- sample(1:k, nrow(df), replace=TRUE)
SSE <- NULL
overall.SSE <- NULL
stopped <- FALSE
while(!stopped){
previous.clusters <- as.vector(df$Cluster)
# remove cluster column for easier calculation
temp <- df
temp$Cluster <- NULL
# Update the centroids
centroids <- UpdateCentroids(df, centroids, k)
#Update each point's associated cluster
df$Cluster <- apply(temp, 1,FindCluster, centroids)
current.clusters <- as.vector(df$Cluster)
inactive.clusters <- ClusterRepCheck(c(1:k), current.clusters)
if (inactive.clusters[1] != 0){
SSEResults <- CentroidSSEVector(df, centroids, inactive.clusters)
active.clusters <- SSEResults$clusters
SSEList <- SSEResults$SSE
for(i in inactive.clusters){
max.index <- which.max(SSEList)
#Get index of first available point
candidate.index <- which(df[,"Cluster"] == active.clusters[1])[1]
# Give that point to the inactive cluster i
df[candidate.index, "Cluster"] <- i
#Remove the used max cluster for the next candidate
active.clusters <- active.clusters[-(max.index)]
SSEList <- SSEList[-(max.index)]
}
}
if (measure.SSE){
#Measure the SSE and add it to the SSE vector
current.SSE <- AllClusterSSE(temp, k, as.vector(df$Cluster))
overall.SSE <- c(overall.SSE, as.numeric(current.SSE))
}
if (StoppingCondition(previous.clusters, current.clusters, DIFF.THRESH)){
stopped <- TRUE
}
}
return (list(Cluster=as.vector(df$Cluster), SSE=overall.SSE))
}
# This function gets the SSE of all active centroids
# This function is used for the redistribution of points
CentroidSSEVector <- function(df, centroids, inactive.clusters){
active.clusters <- setdiff(unique(df$Cluster), inactive.clusters)
SSE <- NULL
for(i in active.clusters){
temp <- subset(df, Cluster == i)
temp$Cluster <- NULL
sum <- sum(as.vector(apply(temp, 1, FUN=function(p1,p2){
return(EuclideanDistance(p1,p2)^2)}, centroids[i,])))
SSE <- append(SSE, sum)
}
return(list(clusters=active.clusters, SSE=SSE))
}
# This function will return the similarity matrix.
# It takes a data frame and a list of clusters as well as a titile of the graph
# Data should be normalized
GetSimilarityMatrix <- function(df, clusters, title){
# Order data by cluster groups
df["Cluster"] <- NA
df$Cluster <- clusters
df <- df[order(df$Cluster),]
df$Cluster <- NULL
sim.matrix <- matrix(data=0, ncol=nrow(df), nrow=nrow(df))
for(i in 1:nrow(df)){
sim.matrix[i,] <- as.vector(apply(df, 1,EuclideanDistance, df[i,]))
}
return(image(sim.matrix, col=topo.colors(10), main=title))
}
# This function returns the SSE value of a data set and its cluster list
# This function is to be used at the end of a run
AllClusterSSE <- function(df, k, clusters){
natt <- ncol(df)
df["Cluster"] <- NA
df$Cluster <- clusters
df <- df[order(df$Cluster),]
centroids <- as.data.frame(matrix(data=0, nrow=k, ncol=natt))
centroids <- UpdateCentroids(df, centroids, k)
#print(df)
SSE <- 0
for(i in 1:k){
temp <- subset(df, Cluster == i)
temp$Cluster <- NULL
#print(temp)
sum <-  sum(as.vector(apply(temp, 1,FUN=function(p1,p2){
return((EuclideanDistance(p1,p2)^2))}, centroids[i,])))
SSE <- SSE + sum
}
return(SSE)
}
setwd("~/Dropbox/CS422 DM/Assignment 5")
iris.kmeans <- iris
iris.kmeans$Species <- NULL
iris.kmeans <- NormalizeData(iris.kmeans, ncol(iris.kmeans))
# K equal to 2
k.two.time <- system.time(k.two.result <- MyKMeans(iris.kmeans, 2))
k.two.clusters <- k.two.result$Cluster
# K equal to 3
k.three.time <- system.time(k.three.result <- MyKMeans(iris.kmeans, 3))
k.three.clusters <- k.three.result$Cluster
# K equal to 4
k.four.time <- system.time(k.four.result <- MyKMeans(iris.kmeans, 4))
k.four.clusters <- k.four.result$Cluster
k.five.time <- system.time(k.five.result <- MyKMeans(iris.kmeans, 5))
k.five.clusters <- k.five.result$Cluster
k.six.time <- system.time(k.six.result <- MyKMeans(iris.kmeans, 6))
k.six.clusters <- k.six.result$Cluster
# Times
print("Times for My K Means")
k.two.time
k.three.time
k.four.time
k.five.time
k.six.time
# Tables
table(iris$Species, k.two.clusters)
table(iris$Species, k.three.clusters)
table(iris$Species, k.four.clusters)
table(iris$Species, k.five.clusters)
sink("./data/myKMeansData.txt", split=T)
# Times
print("Times for My K Means")
k.two.time
k.three.time
k.four.time
k.five.time
k.six.time
# Tables
table(iris$Species, k.two.clusters)
table(iris$Species, k.three.clusters)
table(iris$Species, k.four.clusters)
table(iris$Species, k.five.clusters)
table(iris$Species, k.six.clusters)
# Final SSE Calculation
print("SSE calculation for MyKmeans")
AllClusterSSE(iris.kmeans, 2, k.two.clusters)
AllClusterSSE(iris.kmeans, 3, k.three.clusters)
AllClusterSSE(iris.kmeans, 4, k.four.clusters)
AllClusterSSE(iris.kmeans, 5, k.five.clusters)
AllClusterSSE(iris.kmeans, 6, k.six.clusters)
sink()
GetSimilarityMatrix(iris.kmeans, k.two.clusters, "My K Means: 2 Clusters")
GetSimilarityMatrix(iris.kmeans, k.three.clusters, "My K Means: 3 Clusters")
GetSimilarityMatrix(iris.kmeans, k.four.clusters, "My K Means: 4 Clusters")
GetSimilarityMatrix(iris.kmeans, k.five.clusters, "My K Means: 5 Clusters")
GetSimilarityMatrix(iris.kmeans, k.six.clusters, "My K Means: 6 Clusters")
plot(iris.data, col=k.two.clusters, main="My K Means, K = 2")
plot(iris.kmeans, col=k.two.clusters, main="My K Means, K = 2")
plot(iris.kmeans, col=k.three.clusters, main="My K Means, K = 3")
plot(iris.kmeans, col=k.four.clusters, main="My K Means, K = 4")
plot(iris.kmeans, col=k.five.clusters, main="My K Means, K = 5")
plot(iris.kmeans, col=k.six.clusters, main="My K Means, K = 6")
k.two.result <- MyKMeans(iris.kmeans, 2, TRUE)
k.two.SSE <- k.two.result$SSE
plot(k.two.SSE, c(1:length(k.two.SSE)), xlab="SSE", ylab="Iteration", main="My KMeans, K = 2")
k.three.result <- MyKMeans(iris.kmeans, 3, TRUE)
k.three.SSE <- k.three.result$SSE
plot(k.three.SSE, c(1:length(k.three.SSE)), xlab="SSE", ylab="Iteration", main="My KMeans, K = 3")
k.four.result <- MyKMeans(iris.kmeans, 4, TRUE)
k.four.SSE <- k.four.result$SSE
plot(k.four.SSE, c(1:length(k.four.SSE)), xlab="SSE", ylab="Iteration", main="My KMeans, K = 4")
k.five.result <- MyKMeans(iris.kmeans, 5, TRUE)
k.five.SSE <- k.five.result$SSE
plot(k.five.SSE, c(1:length(k.five.SSE)), xlab="SSE", ylab="Iteration", main="My KMeans, K = 5")
k.six.result <- MyKMeans(iris.kmeans, 6, TRUE)
k.six.SSE <- k.six.result$SSE
plot(k.six.SSE, c(1:length(k.six.SSE)), xlab="SSE", ylab="Iteration", main="My KMeans, K = 6")
iris.data <- iris
iris.data$Species <- NULL
# k = Two
two.time <- system.time(kmeans.two<- kmeans(iris.data, 2))
# k = Three
three.time <-system.time(kmeans.three <- kmeans(iris.data, 3))
# k = Four
four.time <- system.time(kmeans.four <- kmeans(iris.data, 4))
#k = Five
five.time <- system.time(kmeans.five <- kmeans(iris.data, 5))
# K = Six
six.time <- system.time(kmeans.six <- kmeans(iris.data, 6))
sink("./data/builtinKmeansdata.txt", split=T)
# Times for K Means
print("Times for built in kmeans")
two.time
three.time
four.time
five.time
six.time
# Matrices
print("Comparison of real classes and clusters")
table(iris$Species, kmeans.two$cluster)
table(iris$Species, kmeans.three$cluster)
table(iris$Species, kmeans.four$cluster)
table(iris$Species, kmeans.five$cluster)
table(iris$Species, kmeans.six$cluster)
# SSE
print("SSE for KMeans")
kmeans.two$tot.withinss
kmeans.three$tot.withinss
kmeans.four$tot.withinss
kmeans.five$tot.withinss
kmeans.six$tot.withinss
sink()
iris.norm <- NormalizeData(iris.data, ncol(iris.data))
GetSimilarityMatrix(iris.norm, kmeans.two$cluster, "K Means, K = 2")
GetSimilarityMatrix(iris.norm, kmeans.three$cluster, "K Means, K = 3")
GetSimilarityMatrix(iris.norm, kmeans.four$cluster, "K Means, K = 4")
GetSimilarityMatrix(iris.norm, kmeans.five$cluster, "K Means, K = 5")
GetSimilarityMatrix(iris.norm, kmeans.six$cluster, "K Means, K = 6")
plot(iris.data, col=kmeans.two$cluster, main="K Means, K = 2")
plot(iris.data, col=kmeans.three$cluster, main="K Means, K = 3")
plot(iris.data, col=kmeans.four$cluster, main="K Means, K = 4")
plot(iris.data, col=kmeans.five$cluster, main="K Means, K = 5")
plot(iris.data, col=kmeans.six$cluster, main="K Means, K = 6")
i <- sample(1:dim(iris)[1], 40) # Getting 30 samples
iris.sample <- iris[i,]
sink("./data/hierachClustering.txt", split=T)
# Clustering
# Using the average method
hc <- hclust(dist(iris.sample), method="ave")
hc <- hclust(dist(iris.sample), method="ave")
plot(hc, hang= -1,labels=iris$Species[i])
# Using the centroid method
hc <- hclust(dist(iris.sample), method="cen")
plot(hc, hang= -1,labels=iris$Species[i])
i <- sample(1:dim(iris)[1], 30) # Getting 30 samples
iris.sample <- iris[i,]
sink("./data/hierachClustering.txt", split=T)
# Clustering
# Using the average method
hc <- hclust(dist(iris.sample), method="ave")
plot(hc, hang= -1,labels=iris$Species[i])
# Using the centroid method
hc <- hclust(dist(iris.sample), method="cen")
plot(hc, hang= -1,labels=iris$Species[i])
# Using the median method
hc <- hclust(dist(iris.sample), method="median")
plot(hc, hang= -1,labels=iris$Species[i])
hc <- hclust(dist(iris.sample), method="single")
sink("./data/hierachClustering.txt", split=T)
# Clustering
# Using the average method
hc <- hclust(dist(iris.sample), method="ave")
plot(hc, hang= -1,labels=iris$Species[i], main="Cluster: Average Method")
# Using the centroid method
hc <- hclust(dist(iris.sample), method="cen")
plot(hc, hang= -1,labels=iris$Species[i], main="Cluster: Centroid Method")
# Using the median method
hc <- hclust(dist(iris.sample), method="median")
plot(hc, hang= -1,labels=iris$Species[i], main="Cluster: Median Method")
# Using the single method
hc <- hclust(dist(iris.sample), method="single")
plot(hc, hang= -1,labels=iris$Species[i], main="Cluster: Single Method")
rm(i)
sink()
library("fpc")
iris.data <- iris[-5]
sink("./data/dbscanData.txt", split=T)
# Eps 0.4
db1 <- dbscan(iris.data, eps=0.4, MinPts=5)
# Eps 0.5
db2 <- dbscan(iris.data, eps=0.5, MinPts=5)
# Eps 0.6
db3 <- dbscan(iris.data, eps=0.6, MinPts=5)
sink("./data/dbscanData.txt", split=T)
# Comparison Matrices
table(iris$Species, db1$cluster)
table(iris$Species, db2$cluster)
table(iris$Species, db3$cluster)
sink()
# Plots
plotcluster(iris.data,db1$cluster)
plotcluster(iris.data,db2$cluster)
plotcluster(iris.data,db3$cluster)
plotcluster(iris.data,db1$cluster, main="DB Scan: Eps = 0.4")
plotcluster(iris.data,db2$cluster, main="DB Scan: Eps = 0.5")
plotcluster(iris.data,db3$cluster, main="DB Scan: Eps = 0.6")
GetSimilarityMatrix(iris.norm, db1$cluster, "DB Scan: Eps = 0.4")
GetSimilarityMatrix(iris.norm, db2$cluster, "DB Scan: eps = 0.5")
GetSimilarityMatrix(iris.norm, db2$cluster, "DB Scan: Eps = 0.5")
GetSimilarityMatrix(iris.norm, db3$cluster, "DB Scan: Eps = 0.6")
