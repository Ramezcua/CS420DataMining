#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\begin_modules
theorems-ams
eqs-within-sections
figs-within-sections
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 1cm
\rightmargin 2cm
\headsep 1cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Assignment 3: Classification
\end_layout

\begin_layout Author
Ricco Amezcua
\begin_inset Newline newline
\end_inset

CS422 Data Mining
\begin_inset Newline newline
\end_inset

Department of Computer Science
\begin_inset Newline newline
\end_inset

Illinois Institute of Technology
\end_layout

\begin_layout Date
March 26, 2013
\end_layout

\begin_layout Abstract
This is a report for the third assignment of CS422 Data Mining.
 In this report, two data sets are looked at: one about spam emails and
 another about breast cancer.
 Then various classifiers are tested on these data sets to check the accuracy
 of the classifiers.
\end_layout

\begin_layout Section
Problem Statement
\end_layout

\begin_layout Standard
In this report various classifying algorithms are tested.
 They include: support vector machines, neural networks, naive bayes classifier,
 and logistric regression.
 Also, my own interpretation of the perceptron algorithm is also tested.
 The data sets that looked at include a data set involving spam email and
 the other involving breast cancer.
 The spam email data set has various attributes about the emails including
 he frequency of certain characters and phrases.
 The emails are classed into spam or not spam.
 The breast cancer data set contains various medical measurements about
 patients.
 The patients are then classified as being benign or malignant.
 The major difference between these two data sets is size and number of
 attributes.
 The spam data set contains more than 4000 examples with 58 attributes,
 where as the breast cancer data set has less 1000 examples with only 10
 attributes.
 Therefore, the results will show each classifier's adaptability to large
 and small data sets.
 
\end_layout

\begin_layout Section
Proposed Solution
\end_layout

\begin_layout Standard
The data sets were first split up in to training and testing sets.
 80% of the data went to training and 20% went to testing.
 The examples for each set were randomly chosen without replacement.
\end_layout

\begin_layout Standard
The support vector machine, neural network, naive bayes classifier, and
 logistic regression were all from different R packages.
 All attributes for the classifiers were kept at default except for the
 neural network.
 The neural network was given 4 passes to create the network.
 
\end_layout

\begin_layout Standard
For my perceptron algorithm, first the values had to be normalized.
 This was done by first finding the mean and standard deviation of each
 attribute.
 Then each value was subtracted by the mean and then divided by the standard
 deviation.
 After the data had been normalized, the perceptron algorithm was run.
 First an empty set of weights was created and set to 0.
 Then, a vector was created from one example in the data, and an extra attribute
 was added and set to 1.
 This would create the bias.
 The weight vector and example was then multiplied together and 
\emph on
sign 
\emph default
function was used to determine if the multiplication return 1 or -1.
 If the weights correctly classified the class, they were not changed.
 However, if they incorrectly classified the class, the weights had to be
 changed.
 First an error value was created using the actual class minus the classificatio
n.
 This was multiplied by the learning rate (which was set to 0.1) and each
 value in the example vector.
 This was then added to the old weight vector to create a new vector.
 This process was run on every example in the data set.
 To correctly form the weights, the algorithm was ran multiple times using
 the same weights.
 Using the weights from the perceptron, the testing set was classified.
\end_layout

\begin_layout Standard
For every classifier, a confusion matrix was built.
 From each confusiton matrix, the accuracy and error was found, which is
 detailed in table 1 and table 2.
\end_layout

\begin_layout Section
Implementation Details
\end_layout

\begin_layout Standard
The R scripts can be found inside the 
\emph on
code
\emph default
 folder.
 The scripts are separated in to two scripts: question 1, question 2 .
 They are ran by running all of the commands in order.
 The code must be in the same file as the data files.
 The data matrices can be found in the 
\emph on
data 
\emph default
folder.
 The data files will contain the confusion matric for a certain classifier,
 the classifier's accuracy and the error.
\end_layout

\begin_layout Standard
My logistric regression algorithm was not completed in time for the report
 deadline.
\end_layout

\begin_layout Section
Results and Discussion
\end_layout

\begin_layout Standard
Looking at the spam base data in table 1, the support vector machine classifier
 was the most accurate.
 This classifier was also the second most accurate for the breast cancer
 data set.
 In table 2, the naive bayes classifier was 96% accurate.
 However, interestingly, the naive bayes classifier was only 71% accurate
 for the spam base data set.
 This may likely be a reflection on the size of the data set.
 Since the spam base data set contained many more examples, it is possible
 that the naive bayes classifier had a more difficult time classifiying
 all of the examples.
 It may also be that the spam data set had attributes that depended on each
 other, which the naive bayes classifier cannot take in to account.
 It is interesting to note that the naive bayes classifier is the only package
 algorithm to have less than 90% in both tables.
\end_layout

\begin_layout Standard
My perceptron algorithm scored at most 66% in both tables 1 and 2.
 In table 1, having more runs made the classifier less accurate.
 This lower accuracy is not seen in table 2, which may be a reflection on
 the data set size.
 It is uncertain as to what caused the 66% accuracy rating.
 It may either be that the perceptron algorithm is not suited to this type
 of classification or whether there was a user error when implementing the
 algorithm.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[ht] 
\backslash
begin{center} 
\backslash
begin{tabular}{ccc}   
\backslash
hline  & Table 1: Spam Base Classifiers 
\backslash

\backslash
    
\backslash
hline   Classifier & Accuracy & Error
\backslash

\backslash
    SVM & 0.931 & 0.068 
\backslash

\backslash
    Neural Network & 0.928 & 0.071 
\backslash

\backslash
    Naive Bayes & 0.712 & 0.287 
\backslash

\backslash
    Logistic Regression & 0.923 & 0.076 
\backslash

\backslash
    My Perceptron (10 runs) & 0.661 & 0.338 
\backslash

\backslash
    My Perceptron (25 runs) & 0.424 & 0.565 
\backslash

\backslash
     
\backslash
hline 
\backslash
end{tabular} 
\backslash
end{center} 
\backslash
end{table}                   
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[ht] 
\backslash
begin{center} 
\backslash
begin{tabular}{ccc}   
\backslash
hline  & Table 2: Breast Cancer Classifiers 
\backslash

\backslash
    
\backslash
hline   Classifier & Accuracy & Error
\backslash

\backslash
    SVM & 0.954 & 0.045 
\backslash

\backslash
    Neural Network & 0.941 & 0.058 
\backslash

\backslash
    Naive Bayes & 0.964 & 0.035 
\backslash

\backslash
    Logistic Regression & 0.941 & 0.058 
\backslash

\backslash
    My Perceptron (10 runs) & 0.661 & 0.338 
\backslash

\backslash
    My Perceptron (25 runs) & 0.661 & 0.338 
\backslash

\backslash
     
\backslash
hline 
\backslash
end{tabular} 
\backslash
end{center} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\begin_layout Section
References
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset href
LatexCommand href
target "http://cran.r-project.org/manuals.html"

\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset CommandInset href
LatexCommand href
target "http://en.wikipedia.org/wiki/Perceptron"

\end_inset


\end_layout

\end_body
\end_document
